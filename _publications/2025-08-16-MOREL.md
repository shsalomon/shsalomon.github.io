---
title: "Enhancing Adversarial Robustness through Multi-Objective Representation Learning"
permalink: /publications/2025-MOREL
excerpt: 'Enhancing Adversarial Robustness through Multi-Objective Representation Learning'
date: 2025-09-12
venue: 'ICANN 2025, Kaunas, Lithuania'
citation: 'Hotegni, S.S., Peitz, S. (2026). Enhancing Adversarial Robustness Through Multi-objective Representation Learning. In: Senn, W., et al. Artificial Neural Networks and Machine Learning â€“ ICANN 2025. ICANN 2025. Lecture Notes in Computer Science, vol 16068. Springer, Cham. https://doi.org/10.1007/978-3-032-04558-4_35'
---


Deep neural networks (DNNs) are vulnerable to small adversarial perturbations, which are tiny changes to the input data that appear insignificant but cause the model to produce drastically different outputs. Many defense methods require modifying model architectures during evaluation or performing test-time data purification. This not only introduces additional complexity but is often architecture-dependent. We show, however, that robust feature learning during training can significantly enhance DNN robustness. We propose MOREL, a multi-objective approach that aligns natural and adversarial features using cosine similarity and multi-positive contrastive losses to encourage similar features for same-class inputs. Extensive experiments demonstrate that MOREL significantly improves robustness against both white-box and black-box attacks. Our code is available at [https://github.com/salomonhotegni/MOREL](https://github.com/salomonhotegni/MOREL).


[Read paper here](https://link.springer.com/chapter/10.1007/978-3-032-04558-4_35)
